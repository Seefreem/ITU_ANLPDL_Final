{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc05fc7-7592-4e3e-bade-e3f1dc65b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "from linear_probe_utils import *\n",
    "from models import download_and_load_model\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Template Label Counter')\n",
    "parser.add_argument(\"--dataset\",    type=str, action=\"store\", default='trivia_qa') # coqa, trivia_qa\n",
    "parser.add_argument(\"--model\",      type=str, action=\"store\", default='google/gemma-2-2b-it') # meta-llama/Llama-3.1-8B-Instruct\n",
    "parser.add_argument(\"--judge_model\",type=str, action=\"store\", default='google/gemma-2-9b-it')\n",
    "parser.add_argument(\"--output_dir\", type=str, action=\"store\", default='./cache') # required=True, \n",
    "parser.add_argument(\"--data_split\", type=str, action=\"store\", default='train') \n",
    "parser.add_argument(\"--f\", type=str, action=\"store\", default='') \n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "model, tokenizer = download_and_load_model(args.model, args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9a2ce-9dcc-4dfc-a6f1-7a4358e8d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "lr = 1e-4\n",
    "epoch = 10\n",
    "probe_trainer = ProbeTrainer(model.config,bs=bs,lr=lr,epoch=epoch)\n",
    "model_config = model.config\n",
    "model= None\n",
    "tokenizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcfe9b3",
   "metadata": {},
   "source": [
    "# Load dataset and classify them into two classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06519d41-bb4d-4dc4-b4e9-ce7942a3c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifold_learning_isomap_viz import load_judged_data  \n",
    "\n",
    "# workspace\n",
    "workspace_dir = os.path.join(args.output_dir, 'answers', args.dataset, 'train', args.model)\n",
    "test_workspace_dir = os.path.join(args.output_dir, 'answers', args.dataset, 'test', args.model)\n",
    "print(model_config.num_hidden_layers)\n",
    "max_acc_hidden = []\n",
    "for layer in range(model_config.num_hidden_layers):\n",
    "    train_data, train_gt_labels = load_judged_data(workspace_dir, layer)\n",
    "    unknown_data = train_data[train_gt_labels.reshape(-1) == 0.0, :].copy()\n",
    "    unknown_labels = train_gt_labels[train_gt_labels.reshape(-1) == 0.0, :].copy()\n",
    "    train_data = np.concatenate([train_data] + [unknown_data] * 5, axis=0)\n",
    "    train_gt_labels = np.concatenate([train_gt_labels] + [unknown_labels] * 5, axis=0)\n",
    "    train_data = torch.from_numpy(train_data).float()\n",
    "    train_gt_labels = torch.from_numpy(train_gt_labels).float()\n",
    "\n",
    "    test_data, test_gt_labels   = load_judged_data(test_workspace_dir, layer)\n",
    "    test_data = torch.from_numpy(test_data).float()\n",
    "    test_gt_labels = torch.from_numpy(test_gt_labels).float()\n",
    "    # print(train_data.shape)\n",
    "    state_dim = model_config.hidden_size\n",
    "    prober = LinearProbe(state_dim)\n",
    "    optimizer = torch.optim.SGD(prober.parameters(), lr=probe_trainer.lr, momentum=0.9)\n",
    "\n",
    "    test_results,prober = probe_trainer.fit_one_probe(prober, optimizer,\n",
    "                                                      train_data, train_gt_labels,\n",
    "                                                      test_data, test_gt_labels)\n",
    "    max_acc = max(test_results,key=lambda x:x['auroc'])\n",
    "    max_acc_hidden.append(max_acc)\n",
    "    print(layer, max_acc)\n",
    "    # if max_acc[\"acc\"]>0.8:\n",
    "    #     break\n",
    "print(\"probe:\",max_acc_hidden.index(max(max_acc_hidden,key=lambda x:x['auroc'])), \n",
    "      max(max_acc_hidden,key=lambda x:x['auroc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750fd35",
   "metadata": {},
   "source": [
    "meta-llama/Llama-3.1-8B-Instruct:   \n",
    "probe: 26 {'acc': 0.578, 'precision': 0.616, 'recall': 0.746, 'specificity': 0.338, 'macro_f1': 0.536, 'auroc': 0.5420561325420377}  \n",
    "gemma2-9b:  \n",
    "probe: 35 {'acc': 0.539, 'precision': 0.623, 'recall': 0.489, 'specificity': 0.607, 'macro_f1': 0.539, 'auroc': 0.5476651420061696}  \n",
    "2B:   \n",
    "probe: 18 {'acc': 0.477, 'precision': 0.396, 'recall': 0.807, 'specificity': 0.284, 'macro_f1': 0.469, 'auroc': 0.5453987884342413}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e8578-9786-442b-b9cd-0c52860bbca6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([d[\"macro_f1\"] for d in max_acc_hidden],label=\"hidden\")\n",
    "# plt.legend()\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"test macro_f1\")\n",
    "# plt.savefig('hidden_probe_sft0911_1.png')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4692f-1e36-44fc-9b2c-c637abf987e2",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
